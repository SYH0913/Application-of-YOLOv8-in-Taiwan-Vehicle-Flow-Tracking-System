{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 臺灣車流追蹤系統"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 車輛計數-OpenCV\n",
    "        使用 YOLOv8 模型和物件追蹤框架 (abewley/sort) 從影片中偵測和追蹤汽車。\n",
    "        檢測和追蹤是在感興趣的區域進行的。\n",
    "        YOLOv8 是最新、最先進的 YOLO 模型，可用於物件偵測、影像分類和實例分割任務。\n",
    "        SORT 是基於基本資料關聯和狀態估計技術的視覺多物件追蹤框架的準系統實作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考連結\n",
    "    https://github.com/redeagle17/Car-Counting\n",
    "    使用 YOLO 模型進行物體檢測，使用 Sort 算法進行目標追蹤，同時計算穿越指定計數線的車輛數量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classes 類別有哪些?\n",
    "\n",
    "    \n",
    "    classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"potted plant\", \"bed\",\n",
    "              \"dining table\", \"toilet\", \"tv monitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from sort import *\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Video\n",
    "cap = cv2.VideoCapture(\"./KHheighway_video/721836327.118740.mp4\")\n",
    "#寫入一個 VideoWriter 對象，指定儲存的檔案名稱、影片編碼方式、影片幀率和影片尺寸\n",
    "out = cv2.VideoWriter('output_video.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 10, (int(cap.get(3)),int(cap.get(4))))\n",
    "\n",
    "\n",
    "#定義 YOLO 模型預測結果中可能的類別名稱列表 \n",
    "classNames = [\"car\", \"motorbike\", \"bus\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"potted plant\", \"bed\",\n",
    "              \"dining table\", \"toilet\", \"tv monitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "#Load .pt權重檔案\n",
    "model = YOLO(\"yolov8n.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在這裡，mask 是遮罩影像，img 是原始影像。 \n",
    "    位元與運算的規則是，如果兩個對應位元都是 1，則結果中的該位元也是 1，否則為 0。 在這裡，遮罩影像中非零的像素將保留，而原始影像中對應位置的像素將被保留或忽略，這取決於遮罩影像中對應位置的值。\n",
    "\n",
    "    這樣，imgRegion 將包含原始影像中與遮罩影像中非零像素對應的區域，其他區域將被遮罩掉。\n",
    "\n",
    "    這種操作通常用於在影像上提取或突出顯示特定區域，或將影像分割為感興趣的區域。\n",
    "    在這裡，是為了在檢測或計數之前，只關注影像中的特定區域，以提高處理效率或減少誤檢測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#從檔案讀取一個遮罩圖像 (mask.png)，用於指定計數區域。\n",
    "#mask = cv2.imread(\"mask.png\")\n",
    "mask = cv2.imread(\"mask.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用來累計各class\n",
    "car_count = 0\n",
    "bus_count = 0\n",
    "truck_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化 Sort 目標追蹤器，設定最大追蹤幀數 (max_age) 和最小追蹤點數 (min_hits)。\n",
    "tracker = Sort(max_age=70, min_hits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義計數線的兩個端點的座標，定義計數線的座標，[x1, y1, x2, y2]，此處表示一條水平的計數線。\n",
    "lines_coordinates = [300, 420, 630, 420]  # lines_coordinates[0] is one point and lines_coordinates[2] is another point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines_coordinates[1] is height from origin and lines_coordinates[2] is height from origin\n",
    "totalCount = 0\n",
    "visited_id_list = [] #初始化已訪問過的目標 ID 列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 truck, 116.8ms\n",
      "Speed: 2.5ms preprocess, 116.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 150.0ms\n",
      "Speed: 4.0ms preprocess, 150.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 103.1ms\n",
      "Speed: 3.0ms preprocess, 103.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 106.5ms\n",
      "Speed: 2.0ms preprocess, 106.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 109.5ms\n",
      "Speed: 2.0ms preprocess, 109.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 104.8ms\n",
      "Speed: 2.0ms preprocess, 104.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 107.7ms\n",
      "Speed: 3.0ms preprocess, 107.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 99.8ms\n",
      "Speed: 2.0ms preprocess, 99.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 101.0ms\n",
      "Speed: 2.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 116.1ms\n",
      "Speed: 3.0ms preprocess, 116.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 96.5ms\n",
      "Speed: 2.0ms preprocess, 96.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 trucks, 101.5ms\n",
      "Speed: 2.0ms preprocess, 101.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 101.6ms\n",
      "Speed: 2.0ms preprocess, 101.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 91.5ms\n",
      "Speed: 2.0ms preprocess, 91.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 101.5ms\n",
      "Speed: 2.0ms preprocess, 101.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 97.5ms\n",
      "Speed: 4.0ms preprocess, 97.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 92.5ms\n",
      "Speed: 2.0ms preprocess, 92.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 100.9ms\n",
      "Speed: 2.0ms preprocess, 100.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 107.8ms\n",
      "Speed: 2.4ms preprocess, 107.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 90.5ms\n",
      "Speed: 1.0ms preprocess, 90.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 160.2ms\n",
      "Speed: 15.0ms preprocess, 160.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 190.0ms\n",
      "Speed: 4.0ms preprocess, 190.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 102.5ms\n",
      "Speed: 4.0ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 102.5ms\n",
      "Speed: 2.0ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 96.6ms\n",
      "Speed: 2.0ms preprocess, 96.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 100.6ms\n",
      "Speed: 2.0ms preprocess, 100.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 101.5ms\n",
      "Speed: 2.5ms preprocess, 101.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    success, img = cap.read() #讀取影片的一個影格\n",
    "    imgRegion = cv2.bitwise_and(mask, img)  # 將遮罩和影格進行位元運算，獲取檢測區域\n",
    "    results = model(imgRegion, stream=True)  #使用 YOLO 模型檢測區域中的物體。\n",
    "    \n",
    "    #讀取圖形影像，並將其覆蓋到原始影像上。(左上繳裝飾)\n",
    "    imgGraphics = cv2.imread(\"graphics.png\", cv2.IMREAD_UNCHANGED)\n",
    "    img = cvzone.overlayPNG(img, imgGraphics, (0, 0))\n",
    "    \n",
    "    #初始化一個空的數組，用於存儲檢測結果\n",
    "    detections = np.empty((0, 5))\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # To draw bounding box 獲取檢測框的坐標\n",
    "            x1, y1, x2, y2 = box.xyxy[0]  # Gives coordinates to draw bounding box \n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            #cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 0), 3)  顯示檢測框\n",
    "            \n",
    "            #計算檢測框的寬度和高度\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            bbox = (x1, y1, w, h)\n",
    "\n",
    "            # Annotation is required for the detected object 計算檢測框的可信度，並四捨五入至兩位小數。\n",
    "            confidence_level = math.ceil((box.conf[0] * 100)) / 100  # rounding of to 2 decimal places\n",
    "\n",
    "            # To get class name 獲取檢測框的類別名稱。\n",
    "            cls = int(box.cls[0])  # box.cls[0] will give us the class id(float so we need to typecast it) and with\n",
    "            \n",
    "            \n",
    "            # the help of the id will get the class name from classNames list\n",
    "            currentClass = classNames[cls]\n",
    "\n",
    "            #如果檢測到的物體是車輛類別且信度大於 0.3，則進行以下操作。\n",
    "            if currentClass == \"car\" or currentClass == \"motorbike\" or currentClass == \"truck\" or \\\n",
    "                    currentClass == \"bus\" and confidence_level > 0.3:\n",
    "                cvzone.putTextRect(img, f'{currentClass} {confidence_level}', (max(0, x1), max(35, y1)), scale=0.6,\n",
    "                                    thickness=2, offset=3)\n",
    "                cvzone.cornerRect(img, bbox, l=9)\n",
    "                # cornerRect is the  built-in function in cvzone to draw bounding box\n",
    "\n",
    "                #將檢測結果添加到 detections 數組中\n",
    "                currentArray = np.array([x1, y1, x2, y2, confidence_level])  # Check update function in sort.py\n",
    "                detections = np.vstack((detections, currentArray))\n",
    "\n",
    "    #將檢測結果添加到 detections 數組中            \n",
    "    resultTracker = tracker.update(detections)\n",
    "\n",
    "    #在影像上各畫一條紅、綠、藍色的計數線BGR\n",
    "    cv2.line(img, (lines_coordinates[0], lines_coordinates[1]), (lines_coordinates[2], lines_coordinates[3]),\n",
    "             (0, 0, 255), thickness=2)\n",
    "    cv2.line(img, (lines_coordinates[0], lines_coordinates[1]-30), (lines_coordinates[2], lines_coordinates[3]-30),\n",
    "             (0, 255, 0), thickness=2)\n",
    "    cv2.line(img, (lines_coordinates[0], lines_coordinates[1]+30), (lines_coordinates[2], lines_coordinates[3]+30),\n",
    "             (255, 0, 0), thickness=2)\n",
    "\n",
    "    #處理目標追蹤結果\n",
    "    for result in resultTracker:\n",
    "        #獲取目標追蹤結果的座標、寬度和高度\n",
    "        x1, y1, x2, y2, id = result\n",
    "        x1, y1, x2, y2, id = int(x1), int(y1), int(x2), int(y2), int(id)\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        # print(result)\n",
    "        #在影像上標記目標的 ID\n",
    "        cvzone.putTextRect(img, f'{id}', (max(0, x1), max(35, y1)), scale=2.3,\n",
    "                           thickness=2, offset=3)\n",
    "        #在目標的檢測框上畫一個彩色的矩形。\n",
    "        cvzone.cornerRect(img, (x1, y1, w, h), l=9, t=3, rt=2, colorR=(255, 0, 255))\n",
    "\n",
    "        #在目標的中心點處畫一個滿填充的圓形\n",
    "        # Now, we want the center point of the detected object and if it touches the line then increase the count\n",
    "        cx, cy = x1 + w // 2, y1 + h // 2\n",
    "        cv2.circle(img, (cx, cy), 4, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        #如果目標的中心點碰觸到計數線，則進行以下操作。\n",
    "        #可以設置計數範圍\n",
    "        if lines_coordinates[0] < cx < lines_coordinates[2] and lines_coordinates[1] - 30 < cy < lines_coordinates[\n",
    "            1] + 30:\n",
    "            \n",
    "            #如果目標的 ID 還未被訪問，則增加計數，標記已訪問的 ID，並在影像上畫一條綠色的計數線。\n",
    "            if id not in visited_id_list:  # To count the number only once\n",
    "                \n",
    "                #不知道為什麼都是偵測到currentClass == \"bus\"?\n",
    "                #if currentClass == \"car\":\n",
    "                #    car_count += 1\n",
    "                #elif currentClass == \"bus\":\n",
    "                #    bus_count += 1\n",
    "                #elif currentClass == \"truck\":\n",
    "                #    truck_count += 1\n",
    "                \n",
    "                totalCount = totalCount + 1\n",
    "                visited_id_list.append(id)\n",
    "                cv2.line(img, (lines_coordinates[0], lines_coordinates[1]),\n",
    "                         (lines_coordinates[2], lines_coordinates[3]),\n",
    "                         (0, 255, 0), thickness=2)\n",
    "   \n",
    "    #在影像上顯示計數值\n",
    "    cv2.putText(img, str(totalCount), (255, 100), cv2.FONT_HERSHEY_PLAIN, 5, (0, 0, 0), 8)\n",
    "    #cv2.putText(img, f\"Car Count: {car_count}\", (255, 150), cv2.FONT_HERSHEY_PLAIN, 5, (0, 0, 0), 8)\n",
    "    #cv2.putText(img, f\"Bus Count: {bus_count}\", (255, 200), cv2.FONT_HERSHEY_PLAIN, 5, (0, 0, 0), 8)\n",
    "    #cv2.putText(img, f\"Truck Count: {truck_count}\", (255, 250), cv2.FONT_HERSHEY_PLAIN, 5, (0, 0, 0), 8)\n",
    "    #cvzone.putTextRect(img, f'Count {totalCount}', (40, 40), colorT=(255, 255, 255), colorR=(0, 0, 0))\n",
    "\n",
    "    # 寫入影格到 VideoWriter 對象\n",
    "    out.write(img)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    # cv2.imshow(\"Region\", imgRegion)\n",
    "    #cv2.waitKey(1)\n",
    "\n",
    "    #檢查是否按下 'q' 鍵，如果是則釋放影片捕捉器並跳出迴圈\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        break    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一鍵完工\n",
    "    #參考連結:https://github.com/redeagle17/Car-Counting\n",
    "    #使用 YOLO 模型進行物體檢測，使用 Sort 算法進行目標追蹤，同時計算穿越指定計數線的車輛數量。\n",
    "    from ultralytics import YOLO\n",
    "    from sort import *\n",
    "    import cv2\n",
    "    import cvzone\n",
    "    import math\n",
    "    import numpy as np\n",
    "\n",
    "    #Open Video\n",
    "    cap = cv2.VideoCapture(\"./KHheighway_video/721836327.118740.mp4\")\n",
    "    #開啟一個 VideoWriter 對象，指定儲存的檔案名稱、影片編碼方式、影片幀率和影片尺寸\n",
    "    out = cv2.VideoWriter('output_video.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 10, (int(cap.get(3)),int(cap.get(4))))\n",
    "\n",
    "\n",
    "    #定義 YOLO 模型預測結果中可能的類別名稱列表 \n",
    "    classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "                \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "                \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "                \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "                \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"potted plant\", \"bed\",\n",
    "                \"dining table\", \"toilet\", \"tv monitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "                \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "                \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "    #Load .pt權重檔案\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    #從檔案讀取一個遮罩圖像 (mask.png)，用於指定計數區域。\n",
    "    mask = cv2.imread(\"mask.png\")\n",
    "\n",
    "    #初始化 Sort 目標追蹤器，設定最大追蹤幀數 (max_age) 和最小追蹤點數 (min_hits)。\n",
    "    tracker = Sort(max_age=70, min_hits=3)\n",
    "\n",
    "    #定義計數線的兩個端點的座標，定義計數線的座標，[x1, y1, x2, y2]，此處表示一條水平的計數線。\n",
    "    lines_coordinates = [300, 420, 630, 420]  # lines_coordinates[0] is one point and lines_coordinates[2] is another point\n",
    "\n",
    "    #lines_coordinates[1] is height from origin and lines_coordinates[2] is height from origin\n",
    "    totalCount = 0\n",
    "    visited_id_list = [] #初始化已訪問過的目標 ID 列表\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read() #讀取影片的一個影格\n",
    "        imgRegion = cv2.bitwise_and(mask, img)  # 將遮罩和影格進行位元運算，獲取檢測區域\n",
    "        results = model(imgRegion, stream=True)  #使用 YOLO 模型檢測檢測區域中的物體。\n",
    "        \n",
    "        #讀取圖形影像，並將其覆蓋到原始影像上。(左上繳裝飾)\n",
    "        imgGraphics = cv2.imread(\"graphics.png\", cv2.IMREAD_UNCHANGED)\n",
    "        img = cvzone.overlayPNG(img, imgGraphics, (0, 0))\n",
    "        \n",
    "        #初始化一個空的數組，用於存儲檢測結果\n",
    "        detections = np.empty((0, 5))\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                # To draw bounding box 獲取檢測框的坐標\n",
    "                x1, y1, x2, y2 = box.xyxy[0]  # Gives coordinates to draw bounding box \n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                # cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 0), 3)\n",
    "                \n",
    "                #計算檢測框的寬度和高度\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "                bbox = (x1, y1, w, h)\n",
    "\n",
    "                # Annotation is required for the detected object 計算檢測框的置信度，並四捨五入至兩位小數。\n",
    "                confidence_level = math.ceil((box.conf[0] * 100)) / 100  # rounding of to 2 decimal places\n",
    "\n",
    "                # To get class name 獲取檢測框的類別名稱。\n",
    "                cls = int(box.cls[0])  # box.cls[0] will give us the class id(float so we need to typecast it) and with\n",
    "                \n",
    "                \n",
    "                # the help of the id will get the class name from classNames list\n",
    "                currentClass = classNames[cls]\n",
    "\n",
    "                #如果檢測到的物體是車輛類別且信度大於 0.3，則進行以下操作。\n",
    "                if currentClass == \"car\" or currentClass == \"motorbike\" or currentClass == \"truck\" or \\\n",
    "                        currentClass == \"bus\" and confidence_level > 0.3:\n",
    "                    cvzone.putTextRect(img, f'{currentClass} {confidence_level}', (max(0, x1), max(35, y1)), scale=0.6,\n",
    "                                        thickness=2, offset=3)\n",
    "                    cvzone.cornerRect(img, bbox, l=9)\n",
    "                    # cornerRect is the  built-in function in cvzone to draw bounding box\n",
    "\n",
    "                    #將檢測結果添加到 detections 數組中\n",
    "                    currentArray = np.array([x1, y1, x2, y2, confidence_level])  # Check update function in sort.py\n",
    "                    detections = np.vstack((detections, currentArray))\n",
    "\n",
    "        #將檢測結果添加到 detections 數組中            \n",
    "        resultTracker = tracker.update(detections)\n",
    "\n",
    "        #在影像上畫一條紅色的計數線BGR\n",
    "        cv2.line(img, (lines_coordinates[0], lines_coordinates[1]), (lines_coordinates[2], lines_coordinates[3]),\n",
    "                (0, 0, 255), thickness=2)\n",
    "\n",
    "        #處理目標追蹤結果\n",
    "        for result in resultTracker:\n",
    "            #獲取目標追蹤結果的座標、寬度和高度\n",
    "            x1, y1, x2, y2, id = result\n",
    "            x1, y1, x2, y2, id = int(x1), int(y1), int(x2), int(y2), int(id)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            # print(result)\n",
    "            #在影像上標記目標的 ID\n",
    "            cvzone.putTextRect(img, f'{id}', (max(0, x1), max(35, y1)), scale=2.3,\n",
    "                            thickness=2, offset=3)\n",
    "            #在目標的檢測框上畫一個彩色的矩形。\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h), l=9, t=3, rt=2, colorR=(255, 0, 255))\n",
    "\n",
    "            #在目標的中心點處畫一個滿填充的圓形\n",
    "            # Now, we want the center point of the detected object and if it touches the line then increase the count\n",
    "            cx, cy = x1 + w // 2, y1 + h // 2\n",
    "            cv2.circle(img, (cx, cy), 4, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "            #如果目標的中心點碰觸到計數線，則進行以下操作。\n",
    "            if lines_coordinates[0] < cx < lines_coordinates[2] and lines_coordinates[1] - 10 < cy < lines_coordinates[\n",
    "                1] + 10:\n",
    "                #如果目標的 ID 還未被訪問，則增加計數，標記已訪問的 ID，並在影像上畫一條綠色的計數線。\n",
    "                if id not in visited_id_list:  # To count the number only once\n",
    "                    totalCount = totalCount + 1\n",
    "                    visited_id_list.append(id)\n",
    "                    cv2.line(img, (lines_coordinates[0], lines_coordinates[1]),\n",
    "                            (lines_coordinates[2], lines_coordinates[3]),\n",
    "                            (0, 255, 0), thickness=2)\n",
    "    \n",
    "        #在影像上顯示計數值\n",
    "        cv2.putText(img, str(totalCount), (255, 100), cv2.FONT_HERSHEY_PLAIN, 5, (0, 0, 0), 8)\n",
    "        #cvzone.putTextRect(img, f'Count {totalCount}', (40, 40), colorT=(255, 255, 255), colorR=(0, 0, 0))\n",
    "\n",
    "        # 寫入影格到 VideoWriter 對象\n",
    "        out.write(img)\n",
    "\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        # cv2.imshow(\"Region\", imgRegion)\n",
    "        #cv2.waitKey(1)\n",
    "\n",
    "        #檢查是否按下 'q' 鍵，如果是則釋放影片捕捉器並跳出迴圈\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            break    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
